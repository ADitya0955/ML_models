{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8c293ac1-9eb5-4b0b-927e-15e910619cfd",
   "metadata": {},
   "source": [
    "# Importing the necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e4ca32d-6c0a-4aa1-8cad-c1e1649d6b09",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from dateutil.parser import parse\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "325ded71-daf2-4261-9651-481a20f9feca",
   "metadata": {},
   "source": [
    "# Reading the CreditCard dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c5f2e5a-dc91-408e-a363-31bb96273620",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"creditcard.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10b44205-d6e1-43d8-83ad-f95b53025c5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8b52c61-4490-4712-8f59-d9ec14867186",
   "metadata": {},
   "source": [
    "Uploading the dataset to S3 bucket for backup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57fcdfe0-ac8d-4b31-97a7-43277aed97ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sagemaker\n",
    "prefix='sagemaker/credit-card-transactions'\n",
    "sess=sagemaker.Session()\n",
    "\n",
    "uri=sess.upload_data(path=\"./creditcard.csv\",key_prefix=prefix)\n",
    "print(uri)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51993b2b-d83f-4f62-97f3-d0404b02e6cb",
   "metadata": {},
   "source": [
    "# Checking for null values, we have 0 null values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b78e09e1-4161-4df2-9f8f-b96fdf452c06",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b040ba70-b9e9-47f3-b020-36483d860a4e",
   "metadata": {},
   "source": [
    "# Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ac28a7f-a89c-4841-9cb2-b84c830681db",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6721319-86da-4626-b157-8916f2ee1bf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(df.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d72c2253-43eb-47f7-aa6b-b328d2c73085",
   "metadata": {},
   "source": [
    "The below countplot shows that the dataset is highly imbalanced and is leaning towards Class Value 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b800c676-75ed-40bf-92be-bf20fd990feb",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot(x=df['Class'],data=df)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3675a80-61e5-478c-85c7-271c75c2449d",
   "metadata": {},
   "source": [
    "Using pairplot to see the relationship between different variables "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bd4da8f-49f7-4f51-b9fb-f89aeb51db19",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set(style=\"ticks\")\n",
    "sns.pairplot(df[[\"V1\",\"V3\",\"V8\",\"Class\"]], hue=\"Class\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b49a0b8c-ea3e-486d-a006-2e5c4b3eddb2",
   "metadata": {},
   "source": [
    "Correlation Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faa39eba-11f2-4725-accf-63c30f7f6973",
   "metadata": {},
   "outputs": [],
   "source": [
    "correlation_matrix=df.corr()\n",
    "sns.heatmap(correlation_matrix,\n",
    "            xticklabels=correlation_matrix.columns.values,\n",
    "            yticklabels=correlation_matrix.columns.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d853aa39-86a8-4691-8341-1ca0a780792f",
   "metadata": {},
   "source": [
    "# Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7748ef35-af4e-45c4-b893-bf81de10739d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(['Time'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d3a10a3-e83c-4967-a690-36f2b4edf5e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def data_type(dataset):\n",
    "    numerical=[]\n",
    "    categorical=[]\n",
    "    for datatype in dataset.columns:\n",
    "        if df[datatype].dtype==\"float64\" or df[datatype].dtype==\"int64\":\n",
    "            numerical.append(datatype)\n",
    "        else:\n",
    "            categorical.append(datatype)\n",
    "    return numerical,categorical\n",
    "\n",
    "            \n",
    "numerical,categorical=data_type(df)\n",
    "#removing the binary columns from numerical list for scaling\n",
    "def binary_columns(dataset):\n",
    "    binary_cols=[]\n",
    "    for col in dataset.select_dtypes(include=['int','float']).columns:\n",
    "        unique_values=df[col].unique()\n",
    "        if np.in1d(unique_values,[0,1]).all():\n",
    "            binary_cols.append(col)\n",
    "    return binary_cols\n",
    "\n",
    "binary_cols=binary_columns(df)\n",
    "\n",
    "for i in binary_cols:\n",
    "    numerical.remove(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6d81bc2-daaa-41c4-987a-837394601da7",
   "metadata": {},
   "source": [
    "# Scaling the entire dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b3c9055-cd85-441d-b317-d1b3cd5974b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "def feature_scaling(dataset,numerical):\n",
    "    sc_x=StandardScaler()\n",
    "    dataset[numerical]=sc_x.fit_transform(dataset[numerical])\n",
    "    return dataset\n",
    "\n",
    "df=feature_scaling(df,numerical)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7615b9ce-f6f5-4096-9336-102b365a0f78",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd7ec6e4-f690-4632-8de4-03b8c5e1c443",
   "metadata": {},
   "source": [
    "Splitting the data into input(X) and target(y) variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eddf99dd-229e-476f-8895-1aa49a2df987",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(['Class'], axis=1)\n",
    "y = df[['Class']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84f141a5-1d6d-4c6f-b410-f71585d5fad5",
   "metadata": {},
   "source": [
    "# Splitting the data into train and test datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67767ff3-e358-4674-8637-a7b15f69ef72",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.3,random_state=0)\n",
    "\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_test.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12b2e403-065c-4219-b382-a5edf2963b4d",
   "metadata": {},
   "source": [
    "# Need to apply balancing to this highly imbalanced dataset\n",
    "1.If you see the training  score on the original dataset , it is 99.9%\n",
    "\n",
    "    This means that the model has overfitted and has memorized the training data.\n",
    "    This has happened purely because Class attribute in the dataset has more than 99% values as 0\n",
    "\n",
    "2.To tackle this problem, we will use SMOTE over sampling method\n",
    "    \n",
    "    Please keep in mind, we are not going with random undersampling or random oversampling \n",
    "    \n",
    "    Because with random oversampling ,we add random set of copies of minority class examples to the data.\n",
    "    This may increase the likelihood of overfitting.\n",
    "    \n",
    "    Using random undersampling method,we delete data from the majority class.\n",
    "    This can be highly problematic, as the loss of such data can make the decision boundary \n",
    "    between minority and majority instances harder to learn, resulting in a loss in classification performance.\n",
    "\n",
    "3.Hence we are going with SMOTE\n",
    "\n",
    "    It is an oversampling technique where the synthetic samples are generated for the minority class.\n",
    "    This algorithm helps to overcome the overfitting problem posed by random oversampling. \n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09174847-7245-48b0-8eaf-b38c543f8f25",
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE \n",
    "\n",
    "sm = SMOTE(sampling_strategy = 0.9, k_neighbors = 3, random_state = 100) \n",
    "X_train_SMOTE, y_train_SMOTE = sm.fit_resample(X_train, y_train.values.ravel()) \n",
    "  \n",
    "# Print the oversampling results\n",
    "print(f\"\\n\\t After applying SMOTE ,the shape of  X_train: {X_train_SMOTE.shape}\") \n",
    "print(f\"\\n\\t After applying SMOTE ,the shape of y_train: {y_train_SMOTE.shape}\") \n",
    "  \n",
    "print(\"After applying SMOTE, count '1': {}\".format(sum(y_train_SMOTE == 1))) \n",
    "print(\"After applying SMOTE, count '0': {}\".format(sum(y_train_SMOTE == 0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6171fe3-cc61-42ba-87f8-f4d0949550d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_df = pd.DataFrame(X_train_SMOTE)\n",
    "training_df['Class'] = y_train_SMOTE\n",
    "\n",
    "testing_df = pd.DataFrame(X_test)\n",
    "testing_df['Class'] = y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49bc5f72-47d1-4bc7-9250-efee324e489d",
   "metadata": {},
   "source": [
    "Uploading training and test data into CSV files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97eb7182-95c3-4776-9f4b-5674fb76db2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "training_df.to_csv('credit_card_train.csv')\n",
    "testing_df.to_csv('credit_card_test.csv')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02ad3126-3e55-4193-8649-8f368df32317",
   "metadata": {},
   "source": [
    "# Uploading training and test data in S3 Buckets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4920f6c2-a32a-4e10-9a95-991b74344f4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "m_boto3 = boto3.client('sagemaker') \n",
    "\n",
    "sess = sagemaker.Session()\n",
    "\n",
    "region = sess.boto_session.region_name\n",
    "\n",
    "bucket = sess.default_bucket()  #  Bucket is a logical unit of storage in AWS S3\n",
    "\n",
    "print('Using bucket ' + bucket)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45625967-968d-4509-9a0a-a5381b4867a8",
   "metadata": {},
   "source": [
    "Uploading training and test data to S3\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ced87f1-c27c-4b49-b717-ee0eb7814737",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainpath = sess.upload_data(\n",
    "    path='credit_card_train.csv', bucket=bucket,\n",
    "    key_prefix='sagemaker/credit-card-transactions')\n",
    "\n",
    "testpath = sess.upload_data(\n",
    "    path='credit_card_test.csv', bucket=bucket,\n",
    "    key_prefix='sagemaker/credit-card-transactions')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "079b575f-c77f-48f3-b037-e548127c43f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile script.py\n",
    "\n",
    "import argparse\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.externals import joblib\n",
    "from sklearn.metrics import explained_variance_score, r2_score\n",
    "\n",
    "\n",
    "\n",
    "# inference functions ---------------\n",
    "def model_fn(model_dir):\n",
    "    clf = joblib.load(os.path.join(model_dir, \"model.joblib\"))\n",
    "    return clf\n",
    "\n",
    "if __name__ =='__main__':\n",
    "\n",
    "    print('extracting arguments')\n",
    "    parser = argparse.ArgumentParser()\n",
    "\n",
    "    # hyperparameters sent by the client are passed as command-line arguments to the script.\n",
    "   \n",
    "    parser.add_argument('--n-estimators', type=int, default=30)\n",
    "    parser.add_argument('--max_leaf_nodes', type=int, default=5)\n",
    "    parser.add_argument('--max_depth', type=int, default=2)\n",
    "    parser.add_argument('--min_samples_split', type=int, default=3)\n",
    "    parser.add_argument('--random_state', type=int, default=22)\n",
    "    \n",
    "    \n",
    "\n",
    "    # Data, model, and output directories\n",
    "    parser.add_argument('--model-dir', type=str, default=os.environ.get('SM_MODEL_DIR'))\n",
    "    parser.add_argument('--train', type=str, default=os.environ.get('SM_CHANNEL_TRAIN'))\n",
    "    parser.add_argument('--test', type=str, default=os.environ.get('SM_CHANNEL_TEST'))\n",
    "    parser.add_argument('--train-file', type=str, default='credit_card_train.csv')\n",
    "    parser.add_argument('--test-file', type=str, default='credit_card_test.csv')\n",
    "    \n",
    "    \n",
    "    args, _ = parser.parse_known_args()\n",
    "    \n",
    "    print('reading data')\n",
    "    train_df = pd.read_csv(os.path.join(args.train, args.train_file))\n",
    "    test_df = pd.read_csv(os.path.join(args.test, args.test_file))\n",
    "\n",
    "    print('building training and testing datasets')\n",
    "    columns = ['V1', 'V2', 'V3', 'V4', 'V5', 'V6', 'V7', 'V8', 'V9', 'V10', 'V11',\n",
    "       'V12', 'V13', 'V14', 'V15', 'V16', 'V17', 'V18', 'V19', 'V20', 'V21',\n",
    "       'V22', 'V23', 'V24', 'V25', 'V26', 'V27', 'V28', 'Amount']\n",
    "    X_train = train_df[columns]\n",
    "    X_test = test_df[columns]\n",
    "    y_train = train_df['Class']\n",
    "    y_test = test_df['Class']\n",
    "    \n",
    "    # train\n",
    "   \n",
    "    print('training model')\n",
    "    model = RandomForestClassifier(\n",
    "        n_estimators=args.n_estimators,\n",
    "        max_leaf_nodes =args.max_leaf_nodes,\n",
    "        max_depth=args.max_depth,\n",
    "        min_samples_split=args.min_samples_split,\n",
    "        random_state=args.random_state,\n",
    "        n_jobs=1)\n",
    "    \n",
    "    model.fit(X_train, y_train)\n",
    "     \n",
    "    # persist model\n",
    "    path = os.path.join(args.model_dir, \"model.joblib\")\n",
    "    joblib.dump(model, path)\n",
    "    print('model persisted at ' + path)\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99674477",
   "metadata": {},
   "outputs": [],
   "source": [
    "! python script.py --n-estimators 30 \\\n",
    "                   --max-leaf-nodes 5 \\\n",
    "                   --model-dir ./ \\\n",
    "                   --train ./ \\\n",
    "                   --test ./ \\\n",
    "                   --max_depth 2 \\\n",
    "                   --min_samples_split 3  \\\n",
    "                   --random_state 22 \\"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dae79f3e-dde2-4886-b3ef-08e2a45e91ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile requirements.txt\n",
    "\n",
    "scikit-learn\n",
    "pandas\n",
    "numpy\n",
    "argparse\n",
    "fsspec\n",
    "s3fs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b189f415-cf3e-4cce-923f-8d7ea39d51f0",
   "metadata": {},
   "source": [
    "# Using sagemaker estimator to create a training job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cb51583-8cea-4513-bb66-dd989da1c5e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sagemaker.sklearn.estimator import SKLearn\n",
    "\n",
    "sklearn_estimator = SKLearn(\n",
    "    entry_point='script.py',\n",
    "    role = sagemaker.get_execution_role(),\n",
    "    train_instance_count=1,\n",
    "    train_instance_type='ml.c5.2xlarge', \n",
    "    framework_version='0.20.0',\n",
    "    base_job_name='rf-scikit',\n",
    "    #hyperparameteres\n",
    "    hyperparameters = {'n-estimators': 30,\n",
    "                       'max_leaf_nodes': 5,\n",
    "                       'max_depth': 2,\n",
    "                       'min_samples_split': 3,\n",
    "                       'random_state': 22\n",
    "                       })"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dd96657-2613-4b19-80c0-8c02a4710b9b",
   "metadata": {},
   "source": [
    "# Training the model by estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb223f59-9bfb-42fb-96e9-0b2e1b1232b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "sklearn_estimator.fit({'train':trainpath, 'test': testpath})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6044dd4a-ca85-4fc1-9e77-8dc49cb73ed4",
   "metadata": {},
   "source": [
    "# Creating the Model Artifact"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c833bb41-6a2e-403a-b744-37cc0f41bc90",
   "metadata": {},
   "outputs": [],
   "source": [
    "artifact = m_boto3.describe_training_job(\n",
    "    TrainingJobName=sklearn_estimator.latest_training_job.name)['ModelArtifacts']['S3ModelArtifacts']\n",
    "\n",
    "print('Model artifact persisted at ' + artifact)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ef13615-dc3d-487b-a864-3b0c97d00da9",
   "metadata": {},
   "source": [
    "# Deploying the model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08f9730c-0213-464b-b911-63ef62adfd15",
   "metadata": {},
   "source": [
    "This will create an endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ab3112c-a84e-467f-bffc-93698917d927",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor = sklearn_estimator.deploy(instance_type='ml.c5.4xlarge',initial_instance_count=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f20a9b7-2903-42ca-a379-965aaabc41bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = ['V1', 'V2', 'V3', 'V4', 'V5', 'V6', 'V7', 'V8', 'V9', 'V10', 'V11',\n",
    "       'V12', 'V13', 'V14', 'V15', 'V16', 'V17', 'V18', 'V19', 'V20', 'V21',\n",
    "       'V22', 'V23', 'V24', 'V25', 'V26', 'V27', 'V28', 'Amount']\n",
    "\n",
    "predictions = predictor.predict(testing_df[columns])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c74a712-3d22-405e-900f-8f06cea83232",
   "metadata": {},
   "source": [
    "# Evaluating the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7e8a907-8d2d-41a9-b051-0fad4c9cb535",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.metrics import confusion_matrix,classification_report,precision_recall_curve,roc_auc_score\n",
    "\n",
    "print(f\"Classification Report :- \\n {classification_report(y_test, predictions)}\")\n",
    "print(f\"AROC score :- \\n {roc_auc_score(y_test, predictions)}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "951aae92-63bc-4604-97e9-71ab96f34185",
   "metadata": {},
   "source": [
    "The ROC AUC Score score has improved in this model, which shows the model is predicting better now. We would like this score to be as close to 1 as possible."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "542b275a-958f-4a77-98c3-bee6690ef52c",
   "metadata": {},
   "source": [
    "# Confusion Matrix on Balanced data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6f39f61-c584-41c1-888f-09839ca871ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(confusion_matrix(y_test, predictions), annot = True,fmt ='.5g')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfa50d25-3fb5-43f5-adf0-588b2bc2448d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "precision, recall, thresholds = precision_recall_curve(y_test, predictions)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(recall, precision, color='blue')\n",
    "#add axis labels to plot\n",
    "ax.set_title('Precision-Recall Curve')\n",
    "ax.set_ylabel('Precision')\n",
    "ax.set_xlabel('Recall')\n",
    "#display plot\n",
    "plt.show() \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1cb8e19-8de2-445c-8021-01f567ae50ef",
   "metadata": {},
   "source": [
    "In the above curve at (1, 1), the threshold is 0.0.\n",
    "This means that our precision and recall are high, and the model makes distinctions perfectly"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
